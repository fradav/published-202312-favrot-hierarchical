[
  {
    "objectID": "published-202312-favrot-hierarchical.html",
    "href": "published-202312-favrot-hierarchical.html",
    "title": "\n        \n         Supplementary material",
    "section": "",
    "text": "In plant epidemiology, pest and disease presence can be measured in a host population using different metrics. A first metric measures the presence/absence of the pest in the individuals (plants) of the host population. This metric is often called prevalence or incidence (Madden and Hughes (1999), Shaw et al. (2018)). The prevalence describes the proportion of the host population in which the pest is present. This metric is relevant and widely used, but it does not account for the number of pest individuals per host individual. With the prevalence, a plant infected by one single pest individual (e.g., an insect) and a plant infected by many pest individuals both represents one infected plant. For this reason, pest abundance is sometimes assessed using another metric representing the average number of pest individuals per host individual. This metric is called intensity or severity (Madden and Hughes (1999), Shaw et al. (2018)), and describes the intensity of the disease in the target population. These two metrics do not generally have the same requirement in terms of working time; measuring intensity takes indeed much more time than measuring prevalence because it is very tedious to count all pest individuals, especially when individuals are small, numerous, and/or difficult to detect.\nPest prevalence and intensity are commonly measured in factorial field trials to test the efficacy of different treatments. In this paper, we place ourselves in an important application framework which is the evaluation of alternative pesticide treatments to neonicotinoids against aphids in sugar beet. Indeed, neonicotinoids had been a popular chemical treatment to control aphids for many years, especially in sugar beets, a major crop in Europe. Recently, neonicotinoids were recognized as presenting high risks for the environment with a negative impact on a wide range of non-target organisms, including bees (Wood and Goulson (2017), Pisa et al. (2015)), and this familly of pesticides has been banned in several European countries. In order to find a substitute to neonicotinoids, a number of factorial field trials were conducted to compare the efficacy of different alternative treatments during several years in different countries. Each trial consists of a set of plots divided into several blocks, themselves divided into several strips on which different pesticide treatments are randomly allocated. One strip always remains untreated to serve as a control. In each strip, aphid prevalence, aphid intensity or both metrics are measured in a sample of plants (usually, 10-20 plants per strip). Depending on the protocol and on the working time constraint, either one type or both types of metrics are measured. Consequently, for a given pest treatment, some trials may report prevalence data while others report intensity data or both types of data. This heterogeneity raises several issues. A first issue concerns the statistical analysis of the trials reporting prevalence and intensity. Although it is easy to fit a generalized linear model to each type of data separately, it is less straightforward to fit a single model to the whole set of trials in order to obtain a single ranking of the pest treatements taking into account both types of data at the same time. Generally, factorial trials assessing treatment efficacy are analyzed with statistical models that take into account one of the two metrics but not both. Prevalence data are thus commonly analyzed using binomial generalized linear models and intensity data are frequently analyzed with Poisson generalized linear models (Michel, Brun, and Makowski (2017), Laurent et al. (2023), Agresti (2015)). As far as we know, no statistical model has been proposed to assess treatment efficacy based on the simultaneous analysis of prevalence and intensity data. In Osiewalski and Marzec (2019), the authors introduced a switching model designed to handle two count variables, one of which may be degenerate. This model was employed to characterize the counts of cash payments and bank card payments in Poland, utilizing data from both cardholders and non-cardholders. A generalized form of the bivariate negative binomial regression model was developed in Gurmu and Elder (2000), allowing for a more flexible representation of the correlation between the dependent variables. This model was applied to describe the number of visits to a doctor and the number of visits to non-doctor health professionals. It outperformed existing bivariate models across various model comparison criteria. In order to analyze data related to crash counts categorized by severity, Park and Lord (2007) employed a multivariate Poisson-lognormal model, effectively addressing both overdispersion and a fully generalized correlation structure within the dataset. However, it should be noted that these models did not include any binomial distribution and thus could not be used to deal with proportion data, such as pest prevalence. Another issue concerns the practical value of combining both prevalence and intensity data. It is unclear whether the simultaneous analysis of prevalence and intensity data may increase the accuracy of the estimated treatment efficacy compared to the use of a single type of data, and whether this may increase the probability of identifying the most efficient treatments. Finally, it is also unclear how future trials should be designed, in particular how many trials are required to obtain accurate estimations, and whether intensity data should be prefered to prevalence data.\nIn this paper, we propose a new flexible statistical model that can be used to rank pest treatments from trials including prevalence data, intensity data, or both. We apply it to a real dataset including trials testing the efficacy of pesticides against aphids infesting sugar beets, considering contrasted scenarios of data availability, and we show how the proposed model can be used to evaluate the efficacy of different treatments. Based on simulations, we then quantify the reduction of mean absolute errors in the estimated treatment efficacies resulting from the use of both prevalence and intensity data during the statistical inference, compared to the use of either prevalence or intensity data. The rest of the paper is organized as follows. First, we present the structure of the dataset including real prevalence and intensity data. Next, we describe in detail the proposed model, the inference method, and the simulation strategy. After checking the convergence of the fitting algorithm, we show how the model can be used to assess treatement efficacy. We finally present the results based on simulated data and we make several recommendations."
  },
  {
    "objectID": "published-202312-favrot-hierarchical.html#description-of-the-data",
    "href": "published-202312-favrot-hierarchical.html#description-of-the-data",
    "title": "\n        \n         Supplementary material",
    "section": "2.1 Description of the data",
    "text": "2.1 Description of the data\nData are collected in 32 field trials conducted in France, Belgium and the Netherlands to compare several treatments against aphids in sugar beets. Each trial consists in a plot located in a given site at a given year (site-year) divided into one to four blocks. Each of these blocks is itself divided into strips where different treatments are tested, one of these treatments being an untreated control and the others corresponding to different types of insecticide. In each strip of each block, the number of aphids is counted on a sample of 10 beet plants (intensity). The number of infested plants (prevalence) is measured as well, but only in 15 trials out of 32. The total numbers of intensity and prevalence data are equal to 1128 and 561, respectively. Note that the number of aphids is not counted on each beet plant but in the whole plant sample. Intensity and prevalence are monitored at different times after treatments. As shown in Figure 1 A, the dataset is unbalanced as less data are available for the treatment Mavrik-jet compared to the others. Figure 1B shows that the intensity and prevalence tend to increase with time.\n\n\n\n\n\n\n\n\nFigure 1: Description of the dataset. A Number of observations according to the type of insecticide. B Examples of observed number of aphids averaged over the blocks (intensity) and number of infested beets out of ten (prevalence) averaged over the blocks, at different dates for two trials."
  },
  {
    "objectID": "published-202312-favrot-hierarchical.html#model",
    "href": "published-202312-favrot-hierarchical.html#model",
    "title": "\n        \n         Supplementary material",
    "section": "2.2 Model",
    "text": "2.2 Model\n\n2.2.1 Specification\nWe introduce an unobserved variable representing the number of pest individuals (here, aphids) on each plant in a sample of N plants (here, sugar beets). This variable is noted W and is assumed to follow a Poisson probability distribution whose mean value is a function of time.\nWe use the following indexes: i for the trial, j for the treatment, k for the block, t for the time and s for the plant number. The distribution of W_{ijkts} is defined as:\n\n    W_{ijkts}\\sim\\mathcal{P}(\\lambda_{ijkt})\n\\tag{1}\n\n    \\log\\ \\lambda_{ijkt} = \\alpha_0 + \\beta_{0i} + \\gamma_{0j}  + (\\alpha_1 + \\gamma_{1j})\\ X_t + u_{ij} + \\epsilon_{ijkt}\n\\tag{2}\nwith\n\n\\beta_{0i}\\sim\\mathcal{N}(0, \\sigma_0^2)\nu_{ij}\\sim\\mathcal{N}(0, \\chi^2)\n\\epsilon_{ijkt}\\sim\\mathcal{N}(0,\\eta^2)\n\nThe random variables are all assumed independent. The parameters \\alpha_0, \\alpha_1, \\gamma_{0j}, and \\gamma_{1j} are considered as fixed. This model serves as a tool for conducting inference on a population of trials, from which the subset of trials comprising our dataset is assumed to constitute a random sample. In essence, the trials contained within our database are leveraged to estimate the parameter values that characterize a target population, where the tested pest control treatments will be actually implemented. Consequently, all parameters contingent on individual trials have been defined as random effects.\nThe observed variables (intensity and prevalence) can be expressed as a function of W. We note:\n\nY_{ijkt} the number of pest individuals (aphids) in the sample of N_i plants collected in trial i, treatment j, block k, at time t\nZ_{ijkt} the number of infested plants among the N_i plants collected in trial i, treatment j, block k, at time t\n\nThen, assuming the Ws are independent, we have:\n\n    Y_{ijkt} = \\sum\\limits_{s = 1}^{N_i} W_{ijkts}\\ \\hspace{1cm}\\ Y_{ijkt} \\sim \\mathcal{P}(N_{i}\\lambda_{ijkt})\n\\tag{3}\n\n    Z_{ijkt} = \\sum\\limits_{s = 1}^{N_i} \\boldsymbol{1}_{W_{ijkts}&gt;0}\\ \\hspace{1cm} \\ Z_{ijkt} \\sim \\mathcal{B}(N_{i},\\ \\pi_{ijkt})\n\\tag{4}\nwhere \\pi_{ijkt} = 1-\\text{exp}(-\\lambda_{ijkt}). The different quantities used in the model are defined in Table 1.\n\nDescription of the indices, inputs and parameters used in the model\n\n\n\n\n\n\ni\ntrial index\n\n\nj\ntreatment index\n\n\nk\nblock index\n\n\nt\ntime index\n\n\ns\nplant index\n\n\nN_i\nsample size (number of plants)\n\n\n\\lambda_{ijkt}\nmean number of pest individuals (aphids) on one plant\n\n\n\\pi_{ijkt}\nprobability for a plant to be infested\n\n\n\\alpha_0\nmean number of pest individuals (aphids) in the untreated group\n\n\n\\beta_{0i}\ntrial effect\n\n\n\\gamma_{0j}\neffect of treatment j at time 0 (time of treatment)\n\n\n\\alpha_1\ngrowth parameter of the number of pest individuals for the untreated group\n\n\n\\gamma_{1j}\neffect of the treatment on the time effect (interaction between treatment j and time)\n\n\nX_t\nnumber of days post treatment\n\n\nu_{ij}\nrandom interaction between trial and treatment\n\n\n\\epsilon_{ijkt}\nresiduals\n\n\n\nFrom this model we define the efficacy of the jth treatment at time t (t days after pesticide application) by the quantity (Laurent et al. (2023)):\n\n    \\text{Ef}_{jt} = \\Big(1 - \\text{exp}\\big(\\gamma_{0j}+\\gamma_{1j} \\times X_{t}\\big)\\Big) \\times 100\n\\tag{5}\nThe quantity \\text{Ef}_{jt} corresponds to the expected percentage reduction of pest individuals (aphid numbers) for the jth treatment compared to the untreated group, over trials and blocks.\nOur Poisson log linear model includes an additive random dispersion term associated to each individual observation (\\epsilon_{ijkt} in Equation 2). This is a standard and well-recognized approach to deal with over-dispersion (Harrison (2014)). In order to check the model assumptions, we perform a posterior predictive check of our model to check that the data were compatible with the model assumptions. Posterior predictive check is frequently used to look for systematic discrepancies between real and simulated data (Gelman et al. (1995)). To do so, we compute the probability of exceeding each individual data with the fitted model (Equation 2). The computed probabilities are all falling in the range 0.22-0.93 (except for the observations equal to 0, for which the probability of being greater was equal to 1), and are thus not extreme. This result indicates that the model specified is not incompatible with the observed data and that the over-dispersion is correctly taken into account. In addition, we fit another model including a negative binomial distribution instead of a Poisson distribution. The results are almost identical between the two models.\n\n\n2.2.2 Inference on real data\nThe model parameters are estimated using Bayesian inference with a Markov chain Monte-Carlo method. We perform the inference using R, with the package rjags (Plummer (2022)). For each of the six dataset listed in Table 2, we fit the model (Equation 2 - Equation 4) with the following weakly informative priors: \\mathcal{N}(0, 10^3) for the parameters \\alpha_0,\\ \\gamma_0,\\ \\alpha_1,\\ \\gamma_1 and \\mathcal{U}([0, 10]) for the parameters \\sigma_0, \\chi, \\eta. We use two Markov chains with 2 \\times 10^5 iterations (after an adaptating phase of 10^5 iterations), and we center the time variable t to facilitate convergence.\nThe convergence of the MCMC algorithm is checked by inspecting the mixing of the two Markov chains and monitoring the Gelman-Rubin diagnosis statistics (Gelman and Rubin (1992)). We then compute the posterior mean of the pesticide treatment efficacy (defined by Equation 5) as well as its 95% credibility interval. The code used to fit the model is provided below.\n\n\n\n\n\n\nNote\n\n\n\nThe following code presents the inference on an extract of the real dataset, which includes both trials of figure 1B (2020 - B1A97 ; 2020 - u1CwE). It is a demo for the “50% Y - 50% Z” scenario and we set here the number of adaptation and iteration to 2000 in order to reduce computation time.\n\n\n\n\nHide/Show the code\n# Jags code for the model  #################################################\nmodelstringYZ = \"\n    model {\n\n        # Likelihood #####################################################\n        for (i in 1:Q){\n            Y[i] ~ dpois(N[i] * lb[i])\n            Z[i] ~ dbinom(pi[i], N[i])\n\n            log(lb[i]) = beta0[ID[i]] + gamma0[INSEC[i]] + (alpha1 + \n                         gamma1[INSEC[i]]) * TIME[i] + u[ST[i]] + epsi[i]\n\n            pi[i] = 1 - exp(- lb[i])\n            epsi[i] ~ dnorm(0, pi_eps)\n        }\n\n        for (j in 1:K){\n            beta0[j] ~ dnorm(alpha0, tau0)\n        }\n\n        for (c in 1:M){\n            u[c] ~ dnorm(0, invchi)\n        }\n\n        gamma0[1] = 0\n        gamma1[1] = 0\n\n        # Priors #########################################################\n        for (s in 2:L){\n            gamma0[s] ~ dnorm(0, 0.001)\n            gamma1[s] ~ dnorm(0, 0.001)\n        }\n\n        alpha0 ~ dnorm(0, 0.001)\n        alpha1 ~ dnorm(0, 0.001)\n        sigma0 ~ dunif(0, 10)\n        chi ~ dunif(0, 10)\n        eta ~ dunif(0, 10)\n\n        # Derived Quantities #############################################\n        tau0 = pow(sigma0, -2)\n        invchi = pow(chi, -2)\n        pi_eps = pow(eta, -2)\n\n        for (h in 2:L){\n            for(t in 1 : T){\n                Eff[h, t]  = (1 - exp(gamma0[h] + gamma1[h] * \n                             TIME_unique[t])) * 100\n            }\n        }  \n    }\n\"\n\nwriteLines(modelstringYZ, con  =  \"jags_models/modelYZ.txt\")\n############################################################################\n\n\n# Inference example on the extract of the real dataset #####################\nreal_data_extract = readRDS(file = \"data/real_data_extract.rds\")\n\ndata = real_data_extract %&gt;% \n  mutate(tscaled = scale(DPT), st = paste(ID, Insecticide))\n\n# Building scenarios -------------------------------------------------------\nscenarioY = data %&gt;% mutate(Z = NA)\nscenarioYhalfZhalf = data %&gt;% mutate(Y = ifelse(ID == \"2020 - B1A97\", Y, NA), \n                                     Z = ifelse(ID == \"2020 - B1A97\", NA, Z))\nscenarioYhalf = data %&gt;% filter(ID == \"2020 - B1A97\") %&gt;% mutate(Z = NA)\nscenarioZhalf = data %&gt;% filter(ID == \"2020 - u1CwE\") %&gt;% mutate(Y = NA)\n# ---------------------------------------------------------------------------\n\ndata = scenarioYhalfZhalf\n\nY = data$Y;   Q = length(Y);   N = data$N;   Z = data$Z\n\nID = as.numeric(as.factor(as.character(data$ID)));   \nINSEC = as.numeric(as.factor(as.character(data$Insecticide)));   \nTIME = as.numeric(data$tscaled);   \nST = as.numeric(as.factor(as.character(data$st)));   \n\nK = length(unique(ID));   L = length(unique(INSEC));   \nM = length(unique(ST));   \n\ndf_TIME = suppressMessages(data %&gt;% \n                             group_by(DPT, tscaled) %&gt;% \n                             summarise(n = n()) %&gt;% as.data.frame)\n\nTIME_unique = approx(df_TIME$DPT, df_TIME$tscaled, xout = c(6, 12))$y;   \nT = length(unique(TIME_unique))\n\ndata_jags = list(\n  \"Y\" = Y, \"Z\" = Z, \"Q\" =  Q, \"ID\" = ID, \"INSEC\" = INSEC, \n  \"TIME\" = TIME, \"ST\" = ST, \"K\" = K, \"L\" = L, \"M\" = M, \n  \"N\" = N, \"T\" = T, \"TIME_unique\" = TIME_unique\n)\n\nnadapt = 2000;   niter = 2000\n\nmodel &lt;- jags.model(\"jags_models/modelYZ.txt\", data = data_jags, \n                    n.chains = 2, n.adapt = nadapt)\n\nsamples &lt;- coda.samples(model, \n                        variable.names = c(\"gamma0\", \"gamma1\", \"Eff\"), \n                        n.iter = niter, thin = 10)\n############################################################################\n\n\n\nIn practice, it is common that only Y or Z data are available in some of the trials. In this case, the resulting dataset includes observations of Y in some trials and observations of Z in others. The dataset may even include one type of observations only, either Y or Z, in all trials. Here, we define four scenarios with contrasted levels of Y and Z availability in order to evaluate the consequences of using different types of datasets. We consider four data subsets defined from the real dataset including trials with observations of Y, with observations of Z, or with both types of observation in different proportions (Table 2). The data subset “100% Y - 0% Z” includes Y data collected in the 32 trials. The data subset “50% Y - 0% Z” includes Y data collected in the 17 trials for which no Z observation is available. The data subset “0% Y - 50% Z” includes the Z data collected in the 15 trials for which Z observations are available. The data subset “50% Y - 50% Z” includes Y data collected in 17 trials and Z data collected in the other 15 trials. The latter data subset does not include any trial reporting both Y and Z data. Throughout our analysis, missing data are assumed to be missing at random.\nThe hierarchical model defined above is fitted to each dataset in turn. Each fitted model is then used to compute the posterior mean and 95% credibility interval of Ef_{jt} for each treatment at t=6 and 12 days after pesticide application.\n\nFour data subsets defined from the original dataset (real data).\n\n\n\n\n\n\nType of dataset\nDescription\n\n\n\n\n100% Y - 0% Z\nY observations available in the 32 trials and no Z\n\n\n50% Y - 0% Z\nY observations available in 17 trials and no Z\n\n\n0% Y - 50% Z\nZ observations available in 15 trials and no Y\n\n\n50% Y - 50% Z\nY observations available in 17 trials and Z observations available in the other 15 trials\n\n\n\n\n\n2.2.3 Simulations\nSimulations are carried out to further investigate the impact of the type and amount of data available on the accuracy of the parameters and the ability of the model to identify the most and least effective treatments.\nWe define three numbers of trials, equal to 20, 40 and 80, successively. For data simulations, the model parameters are set equal to those estimated from the real dataset “100% Y - 0% Z” defined in Table 2 (posterior means). For each number of trials, we generate virtual data from the model (Equation 1 - Equation 4) and estimate the model parameters, according to the following procedure:\n\nDraw values of \\beta_{0i},\\ u_{ij} and \\epsilon_{ijkt} in their distributions for each trial, 3 treatments (+ the untreated control), 3 dates (t=0, 6, 12), and 4 blocks\nCalculate \\lambda_{ijkt} from Equation 2,\nDraw values of W_{ijkts} in its Poisson distribution for 10 plants (s=1, …, 10)\nCalculate Y_{ijkt} and Z_{ijkt} from the Ws for each trial, treatment, date, block.\nGenerate the eight data subsets corresponding to the scenarios defined in Table 3 (including all values of W, the generated values of Y only, the generated values of Z only, both Y and Z values but not W, the values of Y in 50% of the trials, the values of Z in 50% of the trials, the values of Y in 50% of the trials and the values of Z in the other 50%),\nFit the model (Equation 1 - Equation 4) to each of the data subsets according to the procedure described above based on MCMC.\n\nAt the end of this procedure, we get eight sets of estimated parameters, corresponding to the eight scenarios defined in Table 3. This procedure is repeated 1000 times with each time a different seed between 0 and 999. However, the computations performed with jags failed for 26 replicates and thus 974 replicates were available for the analysis.\nFor each number of trials and each scenario defined in Table 3, the accuracy of the estimated parameters \\gamma (from which depend the treatment efficacies) is evaluated by computing an absolute error, averaged over the three treatments (j=1 corresponding to the control) as:\n\n    E_{\\gamma} = \\frac{1}{2 \\times 3}\\sum\\limits_{j = 2}^{4} \\Big( \\frac{|\\gamma_{0j} - \\hat{\\gamma}_{0j}|}{|\\gamma_{0j}|} + \\frac{|\\gamma_{1j} - \\hat{\\gamma}_{1j}|}{|\\gamma_{1j}|}\\Big)\n\\tag{6}\nwhere the true parameter values are set equal to the posterior means computed with the real dataset, and the parameter estimates (\\hat{\\gamma}_{0j} and \\hat{\\gamma}_{1j}) are the posterior means computed for the jth treatment. For each trial number and each scenario defined in Table 3, the 974 values of E_{\\gamma} obtained for the 974 generated data subsets are then averaged. The average values obtained for the eight scenarios are finally compared to determine the type of data leading to the most accurate estimated parameter values.\nIn addition, we compare the eight scenarios according to another criterion measuring the difference between the estimated efficacy values and the true efficacy value (averaged over the three pesticide treatments considered), as follows:\n\n    E_{\\text{Ef}_{t}}\\ = \\frac{1}{3} \\sum\\limits_{j = 2}^4 \\frac{|\\text{Ef}_{jt} - \\hat{\\text{Ef}}_{jt}|} {|\\text{Ef}_{jt}|}\n\\tag{7}\nwhere the true treatment efficacy is defined by Equation 5 (setting the parameters \\gammas to the posterior means obtained with the real dataset) and the estimated efficacy (\\hat{\\text{Ef}}_{jt}) is the posterior mean computed with the simulated dataset. The 974 values of E_{\\text{Eft}} obtained from the 974 simulated datasets are then averaged for each trial number and each scenario. Finally, we evaluate the proportions of cases where the true best treatment (i.e., the treatment with the highest efficacy) is correctly identified.\nIn order to determine whether the difference of performance obtained with the types of data Y and Z depends on the pest abundance, we perform an additional series of simulations with three values for the model parameter \\alpha_0, equal to -1,\\ 1 and 2, successively. These three values of \\alpha_0 define three contrasted levels of pest abundance (the higher \\alpha_0, the higher the abundance). We used the procedure outlined above considering only two scenarios of data availability, namely “100% Y - 0% Z” and “0% Y - 100% Z”. This procedure is implemented with each value of \\alpha_0 in turn. The results are used to compare the model performances using either Y or Z for parameter estimation, depending of the pest abundance specified by \\alpha_0.\n\nEight scenarios compared using simulated data.\n\n\n\n\n\n\nType of dataset\nDescription\n\n\n\n\n100% W\nW observations available in all the trials\n\n\n100% Y - 0% Z\nY observations available in all the trials\n\n\n0% Y - 100% Z\nZ observations available in all the trials\n\n\n100% Y - 100% Z\nY and Z observations available in all the trials\n\n\n50% Y - 0% Z\nY observations available in half of the trials\n\n\n0% Y - 50% Z\nZ observations available in half of the trials\n\n\n50% Y - 50% Z\nY observations available in half of the trials and Z observations available in the other half of the trials\n\n\n50% Y - 100% Z\nY observations available in half of the trials and Z observations available in all the trials\n\n\n\nThese simulations required a significant amount of computation time and were conducted on the INRAE MIGALE server. For a single seed and 20 trials, the computations took 80 minutes on a computer with an Intel Core i7 processor running at 1.90 GHz and 32 GB of RAM. The code used to perform them is presented below.\n\n\nHide/Show the code\nsimu_data &lt;- function(seed, I){\n \n set.seed(seed)\n \n ID = c(1 : I);   \n \n data = expand_grid(ID = c(1 : I),   Block = c(1 : K),   Band = c(1 : J), \n                    Beet = c(1 : N),   DPT = seq(0, 12, length.out = T))\n \n data = data %&gt;% \n  mutate(Insecticide = ifelse(DPT &lt;= 0, \"T 1\", paste(\"T\", Band)),\n         tscaled = scale(data$DPT)) %&gt;% \n  mutate(st = paste(ID, Insecticide), \n         sbit = paste(ID, Block, Insecticide, DPT))\n \n Insecticide = data$Insecticide %&gt;% unique %&gt;% sort\n names(gamma0) = Insecticide\n names(gamma1) = Insecticide\n \n beta0 = rnorm(I, sd = sig0);   \n u = rnorm(I * J, sd = chi);   \n epsi = rnorm(I * J * K * (T - 1) + I * K, sd = eta);   \n \n names(beta0) = data$ID %&gt;% unique;   \n names(u) = data$st %&gt;% unique\n names(epsi) = data$sbit %&gt;% unique\n \n data = data %&gt;% mutate(alpha0 = alpha0,\n                        alpha1 = alpha1,\n                        N = N,\n                        beta0 = recode(ID, !!!beta0),\n                        gamma0 = recode(Insecticide, !!!gamma0), \n                        gamma1 = recode(Insecticide, !!!gamma1),\n                        u = recode(st, !!!u),\n                        epsi = recode(sbit, !!!epsi))\n \n data$lb = exp(data$alpha0 + data$beta0 + data$gamma0 + \n               (data$alpha1 + data$gamma1) * data$tscaled + \n               data$u + data$epsi)\n \n data$W = sapply(c(1 : (I * J * K * T * N)), \n                 function(x) rpois(1, data$lb[x]))\n \n dataYZ = data %&gt;% group_by(ID, Block, Band, DPT) %&gt;% \n  summarise(Insecticide = unique(Insecticide), \n            tscaled = unique(tscaled), st = unique(st), N = unique(N), \n            Y = sum(W), Z = sum(W &gt; 0)) %&gt;% as.data.frame \n \n dataW = data %&gt;% select(- alpha0, - alpha1, - beta0, - gamma0, - gamma1, \n                         - u, - epsi, - lb)\n \n return(list(\"dataYZ\" = dataYZ, \"dataW\" = dataW))\n}                        \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe following code presents the inference for one seed. As the computing time is growing fast with the number of trials and the number of sampled values, we set here the number of trials to 10 (I = 10) and the number of adaptations and iterations to 2000.\nOur simulation results are obtained by running this code for I = 10, 20, 40, 80, for all seeds between 0 and 999, with a number of adaptations and iterations equal to 36000.\nScenarios “50% Y - 0% Z” and “0% Y - 50% Z” are obtained from scenarios “100% Y - 0% Z” and “0% Y - 100% Z”, respectively. For example “50% Y - 0% Z” scenario with 40 trials corresponds to “100% Y - 0% Z” with 20 trials.\n\n\n\n\nHide/Show the code\nJ = 4;   T = 3;   N = 10;   K = 4;\n\nBlock = c(1 : K);   Band = c(1 : J);   \nBeet = c(1 : N);   DPT = seq(0, 12, length.out = T);     \n\nalpha0 = 0.5;   gamma0 = c(0, - 0.13, - 1.13, - 1.24);       \nalpha1 = 0.16;   gamma1 = c(0, 0.24, - 0.14, - 0.15);\nsig0 = 1.87;   chi = 0.27;   eta = 0.98      \n\n############################################################################\n\n# Building scenarios #######################################################\nseed = 1;   I = 10\ndata = suppressMessages(simu_data(seed = seed, I = I))\n\nscenarios = list(\n  Y = data$dataYZ %&gt;% mutate(Z = NA),\n  Z = data$dataYZ %&gt;% mutate(Y = NA),\n  YhalfZhalf = data$dataYZ %&gt;% mutate(Y = ifelse(ID &lt;= (I / 2), NA, Y), \n                                      Z = ifelse(ID &gt; (I / 2), NA, Z)),\n  YhalfZ = data$dataYZ %&gt;% mutate(Y = ifelse(ID &lt;= (I / 2), NA, Y)),\n  YZ = data$dataYZ,\n  W = data$dataW\n)\n#############################################################################\n\n\n# Inference #################################################################\nnadapt = 2000;   niter = 2000\n\nres_inf = NULL\n\n# Inference YZ --------------------------------------------------------------\nID = as.numeric(as.factor(as.character(scenarios$Y$ID)));   \nINSEC = as.numeric(as.factor(as.character(scenarios$Y$Insecticide)));   \nTIME = as.numeric(scenarios$Y$tscaled);   \nST = as.numeric(as.factor(as.character(scenarios$Y$st)));\n\nK = length(unique(ID));   \nL = length(unique(INSEC));   \nM = length(unique(ST))\n\nTIME_unique = unique(scenarios$Y$tscaled)[2 : 3]  \nT = length(unique(TIME_unique))\n\nfor(i in (1 : 5)){\n  Y = scenarios[[i]]$Y;   Z = scenarios[[i]]$Z;   \n  N = scenarios[[i]]$N;   Q = length(Y)   \n  \n  data_jags = list(\n    \"Y\" = Y, \"Z\" = Z, \"Q\" =  Q, \"ID\" = ID, \"INSEC\" = INSEC, \n    \"TIME\" = TIME, \"ST\" = ST, \"K\" = K, \"L\" = L, \"M\" = M, \n    \"N\" = N, \"T\" = T, \"TIME_unique\" = TIME_unique\n  )\n  \n  model &lt;- jags.model(\"jags_models/modelYZ.txt\", data = data_jags, \n                      n.chains = 2, n.adapt = nadapt)\n  \n  samples &lt;- coda.samples(model, \n                          variable.names = c(\"gamma0\", \"gamma1\", \"Eff\"), \n                          n.iter = niter, thin = 10)\n  \n  bind = list(samples);   \n  names(bind) = paste(\"samples\", names(scenarios)[i], sep = \"_\")\n  \n  res_inf = res_inf %&gt;% append(bind)\n}\n\n# Inference W ---------------------------------------------------------------\nID = as.numeric(as.factor(as.character(scenarios$W$ID)));   \nINSEC = as.numeric(as.factor(as.character(scenarios$W$Insecticide)));   \nTIME = as.numeric(scenarios$W$tscaled);   \nST = as.numeric(as.factor(as.character(scenarios$W$st)));\nSBIT = as.numeric(as.factor(as.character(scenarios$W$sbit)))\n\nK = length(unique(ID));   L = length(unique(INSEC));   \nM = length(unique(ST));   X = length(unique(SBIT))\n\nTIME_unique = unique(scenarios$W$tscaled)[2 : 3]  \nT = length(unique(TIME_unique))\n\nW = scenarios$W$W;   Q = length(W)\n\ndata_jags = list(\n  \"W\" = W, \"Q\" =  Q, \"ID\" = ID, \"INSEC\" = INSEC, \n  \"TIME\" = TIME, \"ST\" = ST,  \"SBIT\" = SBIT, \"K\" = K, \"L\" = L, \n  \"M\" = M, \"X\" = X, \"T\" = T, \"TIME_unique\" = TIME_unique\n)\n\nmodel &lt;- jags.model(\"jags_models/modelW.txt\", data = data_jags, \n                    n.chains = 2, n.adapt = nadapt)\n\nsamples &lt;- coda.samples(model, \n                        variable.names = c(\"gamma0\", \"gamma1\", \"Eff\"), \n                        n.iter = niter, thin = 10)\n\nres_inf = res_inf %&gt;% append(list(\"samples_W\" = samples))\n############################################################################\n\n\n# Formatting results #######################################################\nt = scenarios$Y$tscaled %&gt;% unique\nEff_6_true = (1 - exp(gamma0[2 : J] + gamma1[2 : J] * t[2])) * 100\nEff_12_true = (1 - exp(gamma0[2 : J] + gamma1[2 : J] * t[3])) * 100\ntruth = c(Eff_6_true, Eff_12_true, gamma0[2 : J], gamma1[2 : J])\n\nn_scenarios = length(scenarios)\n\nesti = lapply(\n  res_inf, function(x) summary(x)$statistics %&gt;% as.data.frame %&gt;% \n    rownames_to_column %&gt;% \n    filter(!(grepl(\"gamma\", rowname) & Mean == 0)) %&gt;% \n    select(Mean) %&gt;% as.matrix %&gt;% as.vector\n)    \n\nb_inf = lapply(\n  res_inf, function(x) summary(x)$quantiles %&gt;% as.data.frame %&gt;% \n    rownames_to_column %&gt;% \n    filter(!(grepl(\"gamma\", rowname) & `2.5%` == 0)) %&gt;% \n    select(`2.5%`) %&gt;% as.matrix %&gt;% as.vector\n)    \n\nb_sup = lapply(\n  res_inf, function(x) summary(x)$quantiles %&gt;% as.data.frame %&gt;% \n    rownames_to_column %&gt;% \n    filter(!(grepl(\"gamma\", rowname) & `2.5%` == 0)) %&gt;% \n    select(`97.5%`) %&gt;% as.matrix %&gt;% as.vector\n)    \n\nparameters = summary(res_inf[[1]])$statistics %&gt;% as.data.frame %&gt;% \n  rownames_to_column %&gt;% \n  filter(!(grepl(\"gamma\", rowname) & Mean == 0)) %&gt;% \n  select(rowname) %&gt;% as.matrix %&gt;% as.vector   \n\nres = do.call(rbind, \n              lapply(c(1 : n_scenarios), \n                     function(x) \n                       data.frame(Truth = truth, Scenario = names(scenarios)[x], \n                                  I = I, seed = seed, \n                                  value = esti[[x]], parameters = parameters, \n                                  b_inf = b_inf[[x]], b_sup = b_sup[[x]]\n                       )\n              )\n)\n############################################################################"
  },
  {
    "objectID": "published-202312-favrot-hierarchical.html#results-obtained-with-real-data",
    "href": "published-202312-favrot-hierarchical.html#results-obtained-with-real-data",
    "title": "\n        \n         Supplementary material",
    "section": "3.1 Results obtained with real data",
    "text": "3.1 Results obtained with real data\nWe present here the results obtained with real data. First, we check the convergence of the model for the scenarios defined in Table 2. We then compare the estimated values and the credibility intervals of the treatment efficacy obtained in the different scenarios.\n\n3.1.1 Model convergence and posterior distributions\nFigure 2 presents the Markov chains associated with the model parameters and treatment efficacies for the different scenarios. The x-axis presents the iteration number and the y-axis presents the sampled value. Results show that the chains are well mixed. Figure 3 presents the Gelman-Rubin statistics associated with the model parameters and treatement efficacies as a function of the iterations, for the different scenarios. We observe that this statistics converges to 1, which indicates the convergence of the algorithm.\nTable 4 gives a summary of the posterior distributions of the model parameters and treatment efficacies obtained for the “100% Y - 0% Z” scenario. The significantly positive value of \\alpha_1 indicates that the aphid numbers tend to increase with time in untreated plots. The relatively high value of \\sigma_0 (posterior mean equal to 1.87) reveals a strong variability in aphid numbers between trials. The posterior mean value of \\chi (0.27) suggests that the treatment efficacy varies across trials. The \\gamma_0 parameter is negative for all three treatments, indicating a negative effect of the treatments on the aphid numbers at the time of pesticide spray. The Movento and Teppeki treatments have a similar effect with a posterior mean for \\gamma_0 equal to -1.13 and -1.24, and a standard deviation equal to 0.12 and 0.11, respectively. The effect of treatment Mavrik Jet is weaker as its posterior mean for \\gamma_0 is equal to -0.13 and its standard deviation is equal to 0.16. The \\gamma_1 posterior means are negative for Movento and Teppeki (-0.14 and -0.15), suggesting that the effect of these treatments tend to increase with time, but the posterior mean value is positive for Mavrik Jet (= 0.24), suggesting that the effect of this treatment may decrease with time. However, the 95% credibility intervals of \\gamma_1 include zero and these parameters are not very accurately estimated.\n\n\n\n\n\n\n\n\nFigure 2: Model convergence - Markov chain for the model parameters and treatment efficacies, in the scenarios “50% Y - 0% Z” (A), “50% Y - 50% Z” (B), “100% Y - 0% Z” (C) and “0% Y - 50% Z” (D). The x-axis presents the iteration number and the y-axis presents the sampled value.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Model convergence - Gelman-Rubin statistics for the parameters of the model (Equation 1 - Equation 4) and for treatment efficacies (Equation 5), according to the scenarios “50% Y - 0% Z” (A), “50% Y - 50% Z” (B), “100% Y - 0% Z” (C) and “0% Y - 50% Z” (D). The x-axis presents the iteration number and the y-axis presents the Gelman-Rubin statistic.\n\n\n\n\n\n\n\n\n\n\nSummary of the posterior distributions obtained with the \"100\\% Y - 0\\% Z\" scenario for the model parameters and treatment efficacies: posterior mean, standard deviation, 2.5 and 97.5 quantiles.\n\n\nParameter\nMean\nSD\n2.5%\n97.5%\n\n\n\n\nα₀\n0.49\n0.34\n-0.19\n1.17\n\n\nα₁\n0.16\n0.06\n0.04\n0.29\n\n\nσ₀\n1.87\n0.26\n1.44\n2.46\n\n\nχ\n0.28\n0.06\n0.15\n0.40\n\n\nη\n0.98\n0.03\n0.92\n1.03\n\n\nγ₀ - untreated\n0.00\n0.00\n0.00\n0.00\n\n\nγ₀ - Mavrik Jet\n-0.12\n0.17\n-0.46\n0.20\n\n\nγ₀ - Movento\n-1.13\n0.12\n-1.37\n-0.88\n\n\nγ₀ - Teppeki\n-1.24\n0.11\n-1.46\n-1.02\n\n\nγ₁ - untreated\n0.00\n0.00\n0.00\n0.00\n\n\nγ₁ - Mavrik Jet\n0.24\n0.13\n-0.01\n0.49\n\n\nγ₁ - Movento\n-0.15\n0.10\n-0.33\n0.04\n\n\nγ₁ - Teppeki\n-0.15\n0.09\n-0.32\n0.02\n\n\n\n\n\n\n\n\n\n3.1.2 Estimated values of pesticide treatment efficacies\nFigure 4 presents the posterior means and the 95% credibility intervals of treatment efficacies at 6 days (A) and 12 days (B) after pesticide spray, for the “100% Y - 0% Z”, “50% Y - 50% Z”, “50% Y - 0% Z” and “0% Y - 50% Z” scenarios. Different scenarios are indicated by different colors. The x-axis presents the efficacy and the y-axis presents the treatments. Overall, the results obtained are consistent across scenarios; Teppeki and Movento show higher mean efficacies than Mavrik Jet, and the credibility intervals are narrower for Teppeki and Movento than for Mavrik Jet in all scenarios. The credibility interval of the “100% Y - 0% Z” scenario is narrower than that of the “50% Y - 50% Z” scenario, which is itself narrower than that of the “50% Y - 0% Z” and “0% Y - 50% Z” scenarios. Overall, the credibility interval sizes obtained with the “100% Y - 0% Z” scenario are 25% to 45% smaller than those obtained with the “50% Y - 0% Z” scenario (Table 5), aligning with the principle that increased data availability leads to more precise estimates. Results also indicate that credibility intervals are frequently larger with “0% Y - 50% Z” than with “50% Y - 0% Z,” suggesting that more accurate estimates are achievable using Y compared to Z, at least in this specific case study. Interestingly, the sizes of the credibility intervals are approximately 25% smaller with “50% Y - 50% Z” compared to “50% Y - 0% Z,” demonstrating that the combination of Y and Z observations collected from distinct trials proves beneficial and results in a reduction of uncertainty in the estimated treatment efficacy. This finding underscores the potential enhancement of treatment efficacy estimation through the combination of trials incorporating prevalence data and those incorporating intensity data.\n\n\n\n\n\n\n\n\nFigure 4: Estimated treatment efficacies after 6 days (A) and after 12 days (B), with their credibility intervals. Colors correspond to the different scenarios.\n\n\n\n\n\n\n\n\nDifferences in the sizes of the 95 credibility intervals (CI) of the estimated treatment efficacies for the scenarios \"50\\% Y - 50\\% Z\", \"0\\% Y - 50\\% Z\" and \"100\\% Y - 0\\% Z\", compared to \"50\\% Y - 0\\% Z\". The difference is given in percentage. A positive (negative) value indicates an increase (decrease) of the credibility interval size. The third column indicates differences for the efficacy at 6 days after pesticide spray, and the fourth column indicates the difference for the efficacy at 12 days.\n\n\nInsecticide\nData\nFor efficacy at 6 days\nFor efficacy at 12 days\n\n\n\n\nMavrik Jet\n0% Y - 50% Z\n26.7\n-19.1\n\n\nMovento\n0% Y - 50% Z\n0.8\n-9.8\n\n\nTeppeki\n0% Y - 50% Z\n44.4\n16.9\n\n\nMavrik Jet\n100% Y - 0% Z\n-27.7\n-41.3\n\n\nMovento\n100% Y - 0% Z\n-40.5\n-46.7\n\n\nTeppeki\n100% Y - 0% Z\n-25.6\n-37.8\n\n\nMavrik Jet\n50% Y - 50% Z\n-18.4\n-31.1\n\n\nMovento\n50% Y - 50% Z\n-27.1\n-31.4\n\n\nTeppeki\n50% Y - 50% Z\n-12.1\n-22.4"
  },
  {
    "objectID": "published-202312-favrot-hierarchical.html#results-obtained-by-simulation",
    "href": "published-202312-favrot-hierarchical.html#results-obtained-by-simulation",
    "title": "\n        \n         Supplementary material",
    "section": "3.2 Results obtained by simulation",
    "text": "3.2 Results obtained by simulation\n\n3.2.1 Interest of combining trials with prevalence and trials with intensity\nIn this section, we consider the situation where only one type of observation is available per trial - pest prevalence or pest intensity. We compare the accuracy of the estimated parameters and estimated levels of treatment efficacy obtained by combining both types of trials compared to the results obtained using each set of trials separately.\nThe parameters used to generate the data are given in table 6.\n\n\n\nParameters used to generate virtual data.\n\n\nParameters\nα₀\nα₁\nγ₀₀\nγ₀₁\nγ₀₂\nγ₀₃\nγ₁₀\nγ₁₁\nγ₁₂\nγ₁₃\nσ₀\nη\nχ\n\n\nValues\n0.50\n0.16\n0.00\n-0.13\n-1.13\n-1.24\n0.00\n0.24\n-0.14\n-0.15\n1.87\n0.98\n0.27\n\n\n\n\n\n\n\nFigure 5 represents the E_{\\gamma} (Equation 6) (A), E_{Ef_6} (Equation 7) (B) and E_{Ef_{12}} (Equation 7) (C) evaluation criteria for the “0% Y - 50% Z”, “50% Y - 0% Z” and “50% Y - 50% Z” scenarios (different scenarios are indicated by different colors). The x-axis presents the number of trials and the y-axis the value of the criterion, averaged over the simulated data sets. For each number of trials and for each criterion, we observe that scenario “50% Y - 50% Z” gives a more accurate estimate than scenario “50% Y - 0% Z” which itself gives a more accurate estimate than scenario “0% Y - 50% Z”. For example, for the efficacy at 6 days with 40 trials, the mean absolute error of scenario “50% Y - 0% Z” is 10% less than the mean absolute error of scenario “0% Y - 50% Z” (0.38 vs 0.42). The mean absolute error of scenario “50% Y - 50% Z” is 35% less than that of scenario “0% Y - 50% Z” (0.26 vs 0.42). The values of the three criteria decrease with the number of trials. The E_{\\gamma} criterion decreases from 0.62 with 20 trials to 0.32 with 80 trials for the “50% Y - 50% Z” scenario. A value of 20 trials is therefore not sufficient to obtain an accurate estimate of the parameters.\n\n\n\n\n\n\n\n\nFigure 5: Values of the E_{\\gamma} (Equation 6) (A), E_{Ef_6} (Equation 7) (B) and E_{Ef_{12}} (Equation 7) (C) mean absolute error criteria for the “0% Y - 50% Z”, “50% Y - 0% Z” and “50% Y - 50% Z” scenarios. The x-axis presents the number of trials and the y-axis presents the mean absolute error, averaged over the 974 simulated datasets. Different colors correspond to different scenarios.\n\n\n\n\n\nFigure 6 presents the percentages of cases where the best treatment at 6 days (A) and 12 days (B) has been correctly identified for the “50% Y - 0% Z”, “0% Y - 50% Z” and “50% Y - 50% Z” scenarios. The x-axis presents the number of trials and the y-axis the percentage of cases where the treatment identification is correct. In general, the best treatment is better identified when the number of trials increases. With the “50% Y - 50% Z” scenario, the best treatment at 6 days is well identified in 69% of cases with 20 trials and in 85% of cases with 80 trials. For each number of trials, the percentage of correctly identification is higher for the “50% Y - 50% Z” scenario than for the other two, and the scenario “50% Y - 0% Z” generally gives better results than the scenario “0% Y - 50% Z”, except at 6 days with 20 trials. For example, at 12 days after treatment and with 40 trials, the percentage of correct identification is 5% higher with scenario “50% Y - 50% Z” than with scenario “50% Y - 0% Z” (78 vs 73), and 4% higher with the scenario “50% Y - 0% Z” than with scenario “0% Y - 50% Z” (73 vs 69). These results show the interest of combining prevalence and intensity data for assessing the efficacy of treatments and identifying the best treatments.\n\n\n\n\n\n\n\n\nFigure 6: Comparison of proportion cases where the best treatment is correctly identified in the “0% Y - 50% Z”, “50% Y - 0% Z” and “50% Y - 50% Z” scenarios. The x-axis represents the number of trials and the y-axis represents the percentage of cases where the best treatment has been correctly identified at 6 days (A) and 12 days (B), over the 974 simulated datasets. Different colors correspond to different scenarios.\n\n\n\n\n\n\n\n3.2.2 Interest of adding intensity when prevalence is measured in all trials\nWe now consider a situation where prevalence is measured in each trial and intensity is measured in only some of these trials. We compare the results obtained when the data are combined and when they are used separately. As the prevalence data are usually more accessible in practice and the intensity data more costly, it is important to evaluate the interest of adding intensity data in the statistical analysis.\nThe parameters used to generate the data are the same as in 3.2.1.\nFigure 7 presents the evaluation criteria E_{\\gamma} (Fig 7A), E_{Ef_6} (Fig 7B) and E_{Ef_{12}} (Fig. 7C) for the scenarios “0% Y - 100% Z”, “50% Y - 0% Z”, “50% Y - 100% Z” and “50% Y - 50% Z”. The x-axis presents the number of trials and the y-axis presents the value of the criterion, averaged over the number of simulated data sets. Results show that the mean absolute errors are lower in scenarios “50% Y - 100% Z” and “50% Y - 50% Z” than in “0% Y - 100% Z”, and that the mean absolute errors are lower in the “0% Y - 100% Z” scenario than in the “50% Y - 0% Z” scenario. For example, considering the treatment efficacy at 12 days with 40 trials (Fig. 7C), the mean absolute errors are 13% lower in scenarios “50% Y - 100% Z” and “50% Y - 50% Z” than in “0% Y - 100% Z” (0.30 vs 0.34), and the mean absolute error is 11% lower in “0% Y - 100% Z” than in “50% Y - 0% Z” (0.34 vs 0.38). Clearly, adding intensity data to prevalence data improves the accuracy of the estimations. The mean absolute errors decrease with the number of trials. For example, the E_{\\gamma} criterion decreases from 0.62 with 20 trials to 0.32 with 80 trials for the “50% Y - 50% Z” scenario. As noted above, 20 trials is clearly not sufficient to obtain accurate results.\n\n\n\n\n\n\n\n\nFigure 7: Values of E_{\\gamma} (Equation 6) (A), E_{Ef_6} (Equation 7) (B) and E_{Ef_{12}} (Equation 7) (C) for the “0% Y - 100% Z”, “50% Y - 0% Z”, “50% Y - 100% Z” and “50% Y - 50% Z” scenarios. The x-axis presents the number of trials and the y-axis presents the absolute error averaged over the 974 simulated datasets. Different colors correspond to different scenarios.\n\n\n\n\n\n\n\n3.2.3 Is it better to measure intensity or prevalence in new pest surveys?\nIn order to optimize the design of new pest surveys that might be conducted in the future, we determine which type of observations should be favored. For that purpose, we compare the results obtained with the “100% Y - 0% Z”, “0% Y - 100% Z”, “100% Y / 100% Z” and “100% W” scenarios (recall that W represents the unobserved number of aphids on each plant in the sample (Equation 1)), for different values of \\alpha_0 that defines the average number of infested plants. With \\alpha_0 = -1, the proportion of infested plants is generally much lower than one, while with \\alpha_0 = 2, 100% of plants are generally infested. The case \\alpha_0 = 1 leads to intermediate levels of infestation.\nThe three parameter sets used to generate the data are given in Table 7 and are labeled A, B and C.\n\n\n\nParameters considered for the design of future pest surveys.\n\n\nSet\nα₀\nα₁\nγ₀₀\nγ₀₁\nγ₀₂\nγ₀₃\nγ₁₀\nγ₁₁\nγ₁₂\nγ₁₃\nσ₀\nη\nχ\n\n\nA\n-1.00\n0.16\n0.00\n-0.13\n-1.13\n-1.24\n0.00\n0.24\n-0.14\n-0.15\n1.87\n0.98\n0.27\n\n\nB\n1.00\n0.16\n0.00\n-0.13\n-1.13\n-1.24\n0.00\n0.24\n-0.14\n-0.15\n1.87\n0.98\n0.27\n\n\nC\n2.00\n0.16\n0.00\n-0.13\n-1.13\n-1.24\n0.00\n0.24\n-0.14\n-0.15\n1.87\n0.98\n0.27\n\n\n\n\n\n\n\nFigure 8 (A.1, B.1 and C.1) shows the mean absolute error E_{\\gamma} (Equation 6) as a function of the number of trials for the four scenarios “100% Y - 0% Z”, “0% Y - 100% Z”, “100% Y / 100% Z” and “100% W”. Figure 8 (A.2, B.2 and C.2) shows the distributions of infested plants with 40 trials corresponding to the three values of \\alpha_0 reported in Table 7. In case A (Table 7), the distribution of Z is such that Z is rarely close to 1 and often lower than 0.5 (Figure 8 A.2). In case C, the distribution of Z is such that Z is often very close to 1 (100% of plants infested). Case B is intermediate. The accuracy of the estimated values of the model parameters \\gamma is better with scenario “100% Y - 0% Z” than with scenario “0% Y - 100% Z”, for all number of trials. The advantage of “100% Y - 0% Z” is stronger in case of high pest prevalence (i.e., cases B and C) but very small in case of low pest prevalence (case A). For example, with 20 trials, the mean absolute error is 27% lower in the scenario “100% Y - 0% Z” than in “0% Y - 100% Z” for parameter set C (0.55 vs. 0.75), 10% lower for parameter set B (0.55 vs. 0.62), and not different for parameter set A (0.64). The “100% W” scenario leads to similar results as “100% Y - 0% Z”, regardless of \\alpha_0 and the number of trials. Results obtained with “100% Y / 100% Z” are generally similar to those obtained with “100% Y - 0% Z” and “100% W” but better than those obtained with the scenario “0% Y - 100% Z” in cases B and C. Here again, results show that 20 trials are not sufficient to obtain accurate parameter estimates.\n\n\n\n\n\n\n\n\nFigure 8: Comparison of the “100% Y - 0% Z”, “0% Y - 100% Z”, “100% Y / 100% Z” and “100% W” scenarios according to the distribution of Z and the number of trials, using the E_{\\gamma} criterion (Equation 6). A, B and C correspond to different Z distributions which are given by A.2, B.2 and C.2 (distribution for a number of trials equal to 40). A, B and C respectively correspond to \\alpha_0 = -1, 1 and 2. The details of the simulation parameters are given in table 7. A1, B1 and C1 represent the absolute error E_{\\gamma} averaged over the 974 simulated datasets as a function of the number of trials. Colors correspond to the different scenarios."
  },
  {
    "objectID": "published-202312-favrot-hierarchical.html#model-adjustment-and-comparison-to-the-negative-binomial-model",
    "href": "published-202312-favrot-hierarchical.html#model-adjustment-and-comparison-to-the-negative-binomial-model",
    "title": "\n        \n         Supplementary material",
    "section": "Model adjustment and comparison to the negative binomial model",
    "text": "Model adjustment and comparison to the negative binomial model\nTo check the model’s fit to the data, we performed a posterior predictive check of our model to check that the data were compatible with the model assumptions. To do so, we computed the probability of exceeding each individual data with the fitted model (2). Note that the number of pest individuals per plant are not available in practice; the data correspond to observed numbers of pest individuals for groups of N_i plants. Based on the posterior probability check, the computed probabilities were all falling in the range 0.22-0.93 (except for the observations equal to 0, for which the probability of being greater was equal to 1), and were thus not extreme. This result indicates that the model specified is not incompatible with the observed data and that the over-dispersion was correctly taken into account.\nWe also fitted a new model including a negative binomial distribution instead of a Poisson distribution. The results were almost identical between both types of model. See the figure below.\n\n\n\n\n\nPosterior predictive check, The X-axis is on a logarithmic scale and represents the number of aphids increased by 1.\n\n\n\n\n\n\n\n\n\nObserved vs predicted values"
  }
]